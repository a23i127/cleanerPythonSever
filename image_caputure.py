import os
import requests
from face_filter import contains_face 

# --- ğŸ” Pexels APIã‚­ãƒ¼ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ ---
PEXELS_API_KEY = "3QhQurdrlKiOkl1BqNxsjvIyz8KWHZusb4qJNgyis82VTtYJwhisMWd0"

SEARCH_QUERY = "interior"
SAVE_DIR = "dataset/clean"
PER_PAGE = 15
NUM_PAGES = 10

os.makedirs(SAVE_DIR, exist_ok=True)

headers = {
    "Authorization": PEXELS_API_KEY
}

def download_images():
    # ã™ã§ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ç¢ºèªã—ã¦ count ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆ
    existing_files = [f for f in os.listdir(SAVE_DIR) if f.endswith(".jpg")]
    count = len(existing_files)

    for page in range(1, NUM_PAGES + 1):
        params = {
            "query": SEARCH_QUERY,
            "per_page": PER_PAGE,
            "page": page
        }

        response = requests.get("https://api.pexels.com/v1/search", headers=headers, params=params)
        if response.status_code != 200:
            print(f"âš ï¸ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—ï¼ˆstatus: {response.status_code}ï¼‰")
            continue

        data = response.json()
        for photo in data.get("photos", []):
            url = photo["src"]["large"]
            image_data = requests.get(url).content

            if contains_face(image_data):
                print("ğŸš« é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                continue

            filename = os.path.join(SAVE_DIR, f"clean_{count}.jpg")
            with open(filename, "wb") as f:
                f.write(image_data)
            print(f"âœ… Saved: {filename}")
            count += 1

    print(f"\nğŸ‰ åˆè¨ˆ {count - len(existing_files)} æšã®æ–°ã—ã„ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    download_images()